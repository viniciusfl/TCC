%!TeX root=../tese.tex
%("dica" para o editor de texto: este arquivo é parte de um documento maior)
% para saber mais: https://tex.stackexchange.com/q/78101

\chapter{Related Concepts}

\section**{Natural Language Processing}

According to \textcite{jurafsky2023speech}, Natural Language Processing (NLP) is a field of Artificial Intelligence (AI) dedicated to enabling computers to understand, interpret, and generate human language. Early research in NLP dates back to the 1950s, with initiatives such as the Georgetown–IBM experiment, which successfully translated over sixty sentences from Russian to English \autocite{hutchins2004georgetown}. Since then, the field has evolved from rule-based systems to statistical and, more recently, deep learning approaches.

A major milestone in this evolution was the introduction of embeddings, which are numerical representations of words, sentences, or documents that capture their semantic meaning in a continuous vector space. These representations have become fundamental to modern NLP models, as they're used on a daily basis to power a wide range of applications such as machine translation, sentiment analysis, and information retrieval.

Recent advances in Natural Language Processing (NLP) and Machine Learning have expanded the use of semantic representations beyond traditional text classification or sentiment analysis. In software engineering, these techniques have increasingly been applied to support program comprehension, bug detection, and security auditing. 

The use of embeddings for improving software quality has been explored in multiple research directions. For example, \textcite{li2024hydbre} proposed a hybrid retrieval method for detecting duplicate software bug reports by combining traditional keyword-based retrieval with semantic embeddings to represent the textual descriptions of reports. This combination allowed the system to identify duplicates even when reports used different wording or phrasing to describe the same underlying problem. By leveraging embedding based similarity, the approach outperformed earlier methods that relied solely on text matching, demonstrating the effectiveness of semantic representations in capturing contextual meaning within bug reports.

Another notable example is SICode, which introduced an embedding-based subgraph isomorphism method for bug detection by \textcite{zhang2024sicode}. Instead of relying on computationally expensive exact matching of source code graphs, SICode represents each code structure as a graph embedding, allowing for efficient comparison of code segments based on their semantic and structural similarity. This method enables the detection of previously unseen or variant bugs that share similar logical patterns, significantly,

Embeddings have also been applied to enhance software security analysis. The work Detecting Hard-Coded Credentials in Software Repositories via LLMs leveraged contextual embeddings generated by large language models to identify sensitive information such as passwords and API keys embedded in source code by \textcite{rahman2024credentials}. 

Together, these studies underscore the increasing role of embedding based representations in software engineering research. Whether for identifying duplicate bug reports, detecting structural vulnerabilities, or locating security flaws, embeddings provide a unified framework for capturing semantic and contextual relationships across different data modalities. This growing body of work supports the idea that embedding embedding models achieve comparable performance across diverse software analysis tasks, motivating a deeper investigation into their similarities and differences.

Building upon this context, \textcite{pilone2024deepermatcher} proposed DeeperMatcher, an approach designed to automatically connect user feedback with development issues by leveraging large language models and text embeddings to measure semantic similarity between textual artifacts. Using data from the replication package of \textcite{pilone2024deepermatcher} and other large-scale open-source projects, such as Brave, the study demonstrated how embedding-based similarity can reveal connections between software issues and user reports that would otherwise remain hidden. This work set a relevant precedent for exploring embedding behavior in software engineering scenarios.

\section**{Artificial Intelligence and Embedding Models}

Artificial intelligence (AI) models were originally developed to mimic aspects of human cognition, and they differ significantly from traditional algorithms. Instead of following a fixed set of instructions, an AI model’s behavior is shaped by the data used to train it. Once trained, its outputs result from complex parameter-dependent mathematical computations, sometimes with a stochastic component.

Since many NLP tasks are hard to solve with traditional algorithms, AI models handle text by breaking it into tokens and turning each one into a numerical embedding that represents its meaning. There's no practical way to design these representations by hand, so larger and more data-hungry models usually perform the best. These models often have hundreds of millions or even billions of parameters, and because they require so many resources to train, they're generally referred to as large language models (LLMs).

A fundamental architectural innovation that enabled the development of modern LLMs and embedding models is the Transformer architecture, introduced by \textcite{vaswani2017attention} in the seminal paper ``Attention is All You Need''. The Transformer architecture relies entirely on attention mechanisms, eliminating the need for recurrent or convolutional layers that were previously standard in sequence modeling. This design allows models to process entire sequences in parallel rather than sequentially, dramatically improving training efficiency. The attention mechanism enables the model to weigh the importance of different parts of the input when processing each token, allowing it to capture long-range dependencies and contextual relationships more effectively than previous architectures.

Given the popularity of embedding applications, as seen in the previous section, some models are trained specifically to generate semantic representations (embeddings) that facilitate comparisons between texts. These embedding models are optimized to produce dense vector representations where semantically similar texts are mapped to nearby points in the vector space, enabling efficient similarity calculations and retrieval tasks. Among the popular embedding models available, we find both open-source options such as Jina embeddings, and proprietary models accessed through API services, including OpenAI's embedding models (both large and small variants), Google's Gemini Text Embedding, and Cohere's Embed models. Each of these models employs different architectures and training strategies, while sharing a common goal of producing meaningful vector representations of text.

\section**{Clusterization and Visualization}

As seen in the previous section, embeddings are high-dimensional vectors where semantically similar texts are mapped to nearby points in the vector space. Clusterization is a technique that helps visualize these relationships by grouping similar data points together. In the context of this project, each issue and review is represented as an embedding vectors, and clusterization helps visualize and compare how different embedding models structure this space by identifying which texts are positioned close to each other.

However, visualizing high-dimensional data directly is not possible. To address this, we apply a dimensionality-reduction technique that projects the vectors into a two-dimensional plane while trying to preserve their relative distances and relationships. This allows us to visually inspect how issues and reviews group together and how different embedding models separate or mix these elements.

In this work, the chosen technique for visualization was t-SNE (t-Distributed Stochastic Neighbor Embedding) \autocite{tripathy2021tsne}. t-SNE is widely used for mapping high-dimensional data into 2D or 3D while preserving the local structure of the data. In other words, points that are close in the original embedding space tend to appear close in the 2D visualization.

t-SNE works by:

\begin{itemize}
    \item Modeling similarities between points using probability distributions;

    \item Preserving small-scale, neighborhood relationships rather than global distances;

    \item Allowing non-linear transformation, which makes it effective for detecting clusters in complex data.
\end{itemize}
