%!TeX root=../tese.tex
%("dica" para o editor de texto: este arquivo é parte de um documento maior)
% para saber mais: https://tex.stackexchange.com/q/78101

% As palavras-chave são obrigatórias, em português e em inglês, e devem ser
% definidas antes do resumo/abstract. Acrescente quantas forem necessárias.
\palavraschave{Embeddings. Similaridade Semântica. Processamento de Linguagem Natural. Representação Vetorial de Texto. Avaliação de Modelos.}

\keywords{Embeddings. Semantic Similarity. Natural Language Processing. Vectorial Representation of Text. Model Evaluation.}

\resumo{
    Modelos de embedding têm sido amplamente utilizados em tarefas de Processamento de Linguagem Natural (PLN) para representar textos em espaços vetoriais que capturam suas relações semânticas. Apesar do surgimento de diferentes arquiteturas e técnicas de treinamento, presume-se que, em determinadas tarefas, esses modelos apresentem desempenhos semelhantes. Este trabalho investiga essa hipótese por meio de uma comparação sistemática entre diferentes modelos de embedding aplicados a tarefas de similaridade semântica textual. A partir dos experimentos realizados, buscamos compreender se as diferenças entre modelos usados amplamente no mercado são relevantes para aplicações práticas. Os resultados contribuem para uma melhor compreensão sobre o impacto real da escolha de modelos de embedding em aplicações de PLN.
    }

\abstract{
    Embedding models have been widely used in Natural Language Processing (NLP) tasks to represent texts in vector spaces that capture their semantic relationships. Despite the emergence of different architectures and training techniques, it is presumed that, in certain tasks, these models exhibit similar performance. This work investigates this hypothesis through a systematic comparison of different embedding models applied to semantic textual similarity tasks. From the experiments conducted, we seek to understand whether differences between models used widely in the market are relevant for practical applications. The results contribute to a better understanding of the real impact of choosing embedding models in NLP applications.
}